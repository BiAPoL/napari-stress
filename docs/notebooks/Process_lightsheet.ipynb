{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7fa10e-e1b6-445b-a174-bb56810b8372",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aicsimageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9868\\3043338589.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0maicsimageio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAICSImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnapari_segment_blobs_and_things_with_membranes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnsbatwm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'aicsimageio'"
     ]
    }
   ],
   "source": [
    "from aicsimageio import AICSImage\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm\n",
    "import napari_process_points_and_surfaces as nppas\n",
    "import vedo\n",
    "from skimage import measure\n",
    "\n",
    "import napari\n",
    "import napari_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca80d5-ae6d-42fd-a99d-d939e1bbdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "surface_density = 0.1  # vertices/microns^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02150b4-6822-423e-9645-30acfe271d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:\\Users\\johamuel\\Desktop\\3-001.czi'\n",
    "image = AICSImage(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a6a71-99d6-4b39-919d-532760e931cd",
   "metadata": {},
   "source": [
    "Since we can not move all data to the memory, we shall process one frame at a time. In this notebook, we'll focus on demonstrating the workflow *for a single timepoint*. Still large enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252eaf51-00d7-469b-bd49-4733051b35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.dask_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661616b-7fc0-4412-86d4-c1f1580ea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.asarray(image.physical_pixel_sizes)\n",
    "print('Voxel sizes: ', scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e702ec7-3a8d-426a-8235-bc4907aca228",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.asarray(image.dask_data[0, 0]), name = 'Spheroid', colormap='bop orange',\n",
    "                 scale=scale, blending='additive',\n",
    "                contrast_limits=[154.0, 4410.0])\n",
    "\n",
    "napari.utils.nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9fc8fc-c324-4b66-85b9-9d7ec27fe383",
   "metadata": {},
   "source": [
    "## Droplet analysis\n",
    "\n",
    "before we look at the spheroid, let's have a look at the droplet. Due to the large array size, reshaping the data is not an option, so we'll have to go straight to points and surfaces from here.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Preprocessing follows a slightly different scheme here. The steps include:\n",
    "\n",
    "- Thresholding (simple threshold otsu)\n",
    "- Surface reconstruction (marching cubes)\n",
    "- Surface decimation (We don't need all the >100k vertices of the surface do achieve a good representation)\n",
    "\n",
    "Before we proceed, it makes sense to crop a part of the data which we can reshape to heterotropic voxel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc16bd-7971-4b3c-b7a4-394d9f666a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize and crop the droplet based on its bounding box\n",
    "droplet_binary = nsbatwm.threshold_otsu(image.dask_data[0, 1])\n",
    "props = measure.regionprops_table(droplet_binary, intensity_image=image.dask_data[0, 1], properties=['image', 'bbox', 'image_intensity'])\n",
    "droplet_cropped_bin = props['image'][0]\n",
    "droplet_cropped_int = props['image_intensity'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abebf33-8121-4b01-ab31-07c905487bc6",
   "metadata": {},
   "source": [
    "Since we crop out a part of the image, we need to make sure that we are putting the results at the correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73c891-6bac-404d-8ab0-e7feaceaaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = np.asarray([props[f'bbox-{i}'] for i in range(3)], dtype=int).flatten() * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbf9ad-4c4f-46d7-8693-6dea33e0ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropplet_resampled_int = napari_stress.resample(droplet_cropped_int, vsz=scale[0], vsy=scale[1], vsx=scale[2])\n",
    "\n",
    "viewer.add_labels(droplet_cropped_bin, translate=translate, scale=scale, name='Droplet cropped')\n",
    "viewer.add_image(dropplet_resampled_int, translate=translate, scale=[np.min(scale)]*3, blending='additive', colormap='cyan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835510ed-d3f4-4922-96de-fd1f1b66489b",
   "metadata": {},
   "source": [
    "Now we can retrieve the surface from this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7c021-8163-4df9-81a5-466e5223c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface = list(nppas.label_to_surface(droplet_cropped_bin))\n",
    "surface[0] = surface[0] * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddbef5-dc2f-4911-8075-40e5ee4de3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust vertex density: Distribute N points on surface and recreate surface\n",
    "mesh = vedo.mesh.Mesh((surface[0], surface[1]))\n",
    "vertices = nppas.sample_points_uniformly(surface, number_of_points=int(mesh.area() * surface_density))\n",
    "surf = napari_stress.reconstruct_surface(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1727f-825b-43ce-ab76-337275e06bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust vertex density: Decimate to desired number of vertices\n",
    "mesh = vedo.mesh.Mesh((surf[0], surf[1]))\n",
    "mesh.decimate(N=int(mesh.area() * surface_density))\n",
    "surf = (mesh.points(), np.asarray(mesh.faces()))\n",
    "viewer.add_surface(surf, translate=translate, name='density-adjusted surface')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbda70-910e-4e2b-b029-ec8e449fea65",
   "metadata": {},
   "source": [
    "### Surface refinement\n",
    "\n",
    "With the decimated surface, we can now apply the developed surface tracing method in `napari-stress`. Caveat: Is this legitimate to do for non-isotropic image data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdba687-c853-4f72-a74a-dd15a957aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = napari_stress.trace_refinement_of_surface(dropplet_resampled_int,\n",
    "                                                   (surf[0], surf[1]),\n",
    "                                                   trace_length=30.0, sampling_distance=1,\n",
    "                                                   show_progress=True,\n",
    "                                                   selected_fit_type='quick',\n",
    "                                                   scale=scale,\n",
    "                                                   remove_outliers=True,\n",
    "                                                   interquartile_factor=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a12e3-9daf-40c0-9098-0bb44f89fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_layer = viewer.add_points(np.stack(result.surface_points.to_numpy()), size=1, face_color='orange', translate=translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771a35a-98d4-48a9-b034-e8c704bb37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_layer.world_to_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7904f-ab1f-4d4a-a859-66741470b967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59dba5-45f5-4009-9e03-81449b0751ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
